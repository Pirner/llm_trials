{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f2877bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 2.0.2\n",
      "matplotlib version: 3.10.3\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.7.1+cu118\n",
      "tqdm version: 4.67.1\n",
      "tensorflow version: 2.19.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"numpy\",       # PyTorch & TensorFlow dependency\n",
    "    \"matplotlib\",  # Plotting library\n",
    "    \"tiktoken\",    # Tokenizer\n",
    "    \"torch\",       # Deep learning library\n",
    "    \"tqdm\",        # Progress bar\n",
    "    \"tensorflow\",  # For OpenAI's pretrained weights\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f422cda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "\n",
    "    # The book originally contained this unnecessary \"else\" clause:\n",
    "    #else:\n",
    "    #    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    #        text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c8eccb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "693f7827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7314d162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08f1c839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2810402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbd185f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea429c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d919995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3be60517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    # and increase the max length by +1, which will add one extra\n",
    "    # padding token below\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst = []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to batch_max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # Via padded[:-1], we remove the extra padded token\n",
    "        # that has been added via the +1 setting in batch_max_length\n",
    "        # (the extra padding token will be relevant in later codes)\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efb61fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8322f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cedf031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de0ed307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5213eebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10ee6827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],  # 1st training example\n",
    "     [-0.5, 1.5]]  # 2nd training example\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "\n",
    "\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e662745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]  # New 3rd training example\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d962c250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35d8e7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is much faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fff8a81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76221452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c5ab5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdf96924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b12a2e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
      "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a7965cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
      "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
      "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2c68189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\355M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\355M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\355M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "# If the `previous_chapters.py` file is not available locally,\n",
    "# you can import it from the `llms-from-scratch` PyPI package.\n",
    "# For details, see: https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg\n",
    "# E.g.,\n",
    "# from llms_from_scratch.ch04 import GPTModel\n",
    "# from llms_from_scratch.ch05 import download_and_load_gpt2, load_weights_into_gpt\n",
    "\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a02fc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68cd579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    generate,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "# Alternatively:\n",
    "# from llms_from_scratch.ch05 import (\n",
    "#    generate,\n",
    "#    text_to_token_ids,\n",
    "#    token_ids_to_text\n",
    "# )\n",
    "\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dacbef2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "response_text = (\n",
    "    generated_text[len(input_text):]\n",
    "    .replace(\"### Response:\", \"\")\n",
    "    .strip()\n",
    ")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "261ecaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    calc_loss_loader,\n",
    "    train_model_simple\n",
    ")\n",
    "# Alternatively:\n",
    "# from llms_from_scratch.ch05 import (\n",
    "#    calc_loss_loader,\n",
    "#    train_model_simple,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e141cc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.8259088516235353\n",
      "Validation loss: 3.7619335651397705\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4dc5b865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
      "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.102\n",
      "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.944\n",
      "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
      "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
      "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
      "Ep 1 (Step 000030): Train loss 0.799, Val loss 0.836\n",
      "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
      "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
      "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.789\n",
      "Ep 1 (Step 000050): Train loss 0.663, Val loss 0.783\n",
      "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.763\n",
      "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
      "Ep 1 (Step 000065): Train loss 0.653, Val loss 0.735\n",
      "Ep 1 (Step 000070): Train loss 0.532, Val loss 0.729\n",
      "Ep 1 (Step 000075): Train loss 0.569, Val loss 0.728\n",
      "Ep 1 (Step 000080): Train loss 0.605, Val loss 0.725\n",
      "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.709\n",
      "Ep 1 (Step 000090): Train loss 0.562, Val loss 0.691\n",
      "Ep 1 (Step 000095): Train loss 0.500, Val loss 0.681\n",
      "Ep 1 (Step 000100): Train loss 0.503, Val loss 0.677\n",
      "Ep 1 (Step 000105): Train loss 0.564, Val loss 0.670\n",
      "Ep 1 (Step 000110): Train loss 0.554, Val loss 0.666\n",
      "Ep 1 (Step 000115): Train loss 0.508, Val loss 0.664\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Ep 2 (Step 000120): Train loss 0.435, Val loss 0.672\n",
      "Ep 2 (Step 000125): Train loss 0.451, Val loss 0.686\n",
      "Ep 2 (Step 000130): Train loss 0.447, Val loss 0.682\n",
      "Ep 2 (Step 000135): Train loss 0.405, Val loss 0.682\n",
      "Ep 2 (Step 000140): Train loss 0.410, Val loss 0.681\n",
      "Ep 2 (Step 000145): Train loss 0.368, Val loss 0.681\n",
      "Ep 2 (Step 000150): Train loss 0.382, Val loss 0.675\n",
      "Ep 2 (Step 000155): Train loss 0.413, Val loss 0.675\n",
      "Ep 2 (Step 000160): Train loss 0.415, Val loss 0.683\n",
      "Ep 2 (Step 000165): Train loss 0.379, Val loss 0.686\n",
      "Ep 2 (Step 000170): Train loss 0.323, Val loss 0.681\n",
      "Ep 2 (Step 000175): Train loss 0.337, Val loss 0.669\n",
      "Ep 2 (Step 000180): Train loss 0.392, Val loss 0.656\n",
      "Ep 2 (Step 000185): Train loss 0.415, Val loss 0.658\n",
      "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.648\n",
      "Ep 2 (Step 000195): Train loss 0.329, Val loss 0.635\n",
      "Ep 2 (Step 000200): Train loss 0.310, Val loss 0.635\n",
      "Ep 2 (Step 000205): Train loss 0.352, Val loss 0.632\n",
      "Ep 2 (Step 000210): Train loss 0.367, Val loss 0.631\n",
      "Ep 2 (Step 000215): Train loss 0.395, Val loss 0.634\n",
      "Ep 2 (Step 000220): Train loss 0.301, Val loss 0.648\n",
      "Ep 2 (Step 000225): Train loss 0.347, Val loss 0.661\n",
      "Ep 2 (Step 000230): Train loss 0.295, Val loss 0.656\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
      "Training completed in 148.30 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba9d0a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from previous_chapters import plot_losses\n",
    "# Alternatively:\n",
    "# from llms_from_scratch.ch05 import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2484450d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "678a816b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saved model to disk.\n"
     ]
    }
   ],
   "source": [
    "torch.save({\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "        \"model_and_optimizer.pth\"\n",
    "    )\n",
    "print('[INFO] saved model to disk.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fde1ffdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
    "model_reloaded = GPTModel(BASE_CONFIG)\n",
    "model_reloaded.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model_reloaded.to(device)\n",
    "model_reloaded.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe13117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in test_data[3:6]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model_reloaded,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea47a89c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_trials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
